{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"predictor_final.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPvl0byAPXNbEqeOTp+skqH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"I8YbcRL9azbP","colab_type":"code","outputId":"45c7df86-0dab-4bb5-aa72-9c86ac8dd025","executionInfo":{"status":"ok","timestamp":1591711234197,"user_tz":-120,"elapsed":400619,"user":{"displayName":"Crimson Scythe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5YhYZZnuEHi2VZkAlStFjE7_YgNaUtzkOGVFQ4w=s64","userId":"06715690238472200405"}},"colab":{"base_uri":"https://localhost:8080/","height":145}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import functools\n","import numpy as np\n","import pandas as pd\n","import tensorflow_datasets as tfds\n","from tensorflow.python.keras import regularizers\n","\n","\n","# prepare kaggle dataset\n","###################\n","\n","df = pd.read_json(\"test_set.json\")\n","# print(df)\n","Xd = df.iloc[: , 1]\n","# print(Xd)\n","kaggle_x = Xd.to_numpy()\n","\n","# use the ids as dummy y values.\n","# makes code reuse easier. they do not impact the results whatsoever.\n","\n","ids_kaggle = df.iloc[:, 0]\n","\n","###################\n","\n","# prepare LIAR dataset\n","# ##################\n","\n","def func(x):\n","    if (x==\"true\" or x==\"mostly-true\" or x==\"half-true\"):\n","        return 1\n","    elif(x==\"false\" or x==\"barely-true\" or x==\"pants-fire\" ):\n","        return 0\n","\n","df_liar = pd.read_csv('test.tsv', sep='\\t')\n","Xd = df_liar.iloc[:,2]\n","Yd = df_liar.iloc[:,1]\n","\n","X_arr = Xd.to_numpy()\n","print(X_arr.shape)\n","Y_arr = Yd.map(func)\n","Y_arr = Y_arr.to_numpy()\n","\n","liar_x = X_arr\n","liar_y = Y_arr\n","\n","####################\n","\n","BATCH_SIZE = 1\n","\n","train_data = pd.read_csv(\"train.csv\")\n","valid_data = pd.read_csv(\"valid.csv\")\n","test_data = pd.read_csv(\"test.csv\")\n","\n","\n","train_x = train_data['content'].to_numpy()\n","train_y = train_data['type_id'].to_numpy()\n","\n","valid_x = valid_data['content'].to_numpy()\n","valid_y = valid_data['type_id'].to_numpy()\n","\n","test_x = test_data['content'].to_numpy()\n","test_y = test_data['type_id'].to_numpy()\n","\n","\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","valid_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n","liar_dataset = tf.data.Dataset.from_tensor_slices((liar_x, liar_y))\n","kaggle_dataset = tf.data.Dataset.from_tensor_slices(kaggle_x)\n","\n","tokenizer = tfds.features.text.Tokenizer()\n","\n","vocabulary_set = set()\n","\n","# only build vocabulary on training set\n","for content, _ in train_dataset:\n","  some_tokens = tokenizer.tokenize(content.numpy())\n","  vocabulary_set.update(some_tokens)\n","\n","vocab_size = len(vocabulary_set)\n","\n","encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n","\n","\n","def encode(text_tensor, label):\n"," \n","  encoded_text = encoder.encode(text_tensor.numpy())\n","  return encoded_text, label\n","\n","def encode_map_fn(text, label):\n","  \n","  encoded_text, label = tf.py_function(encode, \n","                                       inp=[text, label], \n","                                       Tout=(tf.int64, tf.int64))\n","\n","  encoded_text.set_shape([None])\n","  label.set_shape([])\n","\n","  return encoded_text, label\n","\n","\n","def encode_kaggle(text_tensor):\n","  \n","  encoded_text = encoder.encode(text_tensor.numpy())\n","  return encoded_text,\n","\n","\n","def encode_kaggle_map_fn(text):\n","\n","  encoded_text = tf.py_function(encode_kaggle, inp=[text], Tout=tf.int64)\n","  encoded_text.set_shape([None])\n","  return encoded_text,\n","\n","\n","\n","train_encoded_data = train_dataset.map(encode_map_fn)  \n","valid_encoded_data = valid_dataset.map(encode_map_fn)  \n","test_encoded_data = test_dataset.map(encode_map_fn)\n","liar_encoded_data = liar_dataset.map(encode_map_fn)\n","kaggle_encoded_data = kaggle_dataset.map(encode_kaggle_map_fn)\n","\n","\n","train_batches = train_encoded_data.padded_batch(BATCH_SIZE)\n","valid_batches = valid_encoded_data.padded_batch(BATCH_SIZE)\n","test_batches = test_encoded_data.padded_batch(BATCH_SIZE)\n","liar_batches = liar_encoded_data.padded_batch(BATCH_SIZE)\n","kaggle_batches = kaggle_encoded_data.padded_batch(BATCH_SIZE)\n","\n","\n","embedding_dim=8\n","\n","model = keras.Sequential([\n","  layers.Embedding(encoder.vocab_size, embedding_dim, ),\n","  layers.GlobalAveragePooling1D(),\n","  layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2()),\n","  layers.Dense(1)\n","])\n","\n","# model.summary()\n","\n","\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","history = model.fit(\n","    train_batches,\n","    validation_data=valid_batches,\n","    epochs=1,\n","    )\n","\n","\n","\n","result = model.evaluate(liar_batches)\n","result2 = model.evaluate(test_batches)\n","\n","\n","#####################\n","\n","predictions = (model.predict(kaggle_batches) > 0.5).astype(\"int32\")\n","\n","\n","truecounts=0\n","falsecounts=0\n","for res in predictions:\n","  if (res[0]==0):\n","      falsecounts+=1\n","  else:\n","      truecounts+=1    \n","\n","print(falsecounts)\n","print(truecounts)\n","\n","####################\n","\n","def decodeKaggle(x):\n","  if (x == 0):\n","    return 'FAKE'\n","  else:\n","    return 'TRUE'  \n","\n","labels = pd.DataFrame(data=predictions, columns=['label']).applymap(decodeKaggle)\n","ids_kaggle = ids_kaggle.to_frame()\n","ids_kaggle.columns = ['id']\n","\n","kaggle_res = ids_kaggle.join(labels)\n","\n","kaggle_res.to_csv('predictions.csv', index=False)\n","\n","####################\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1266,)\n","40000/40000 [==============================] - 366s 9ms/step - loss: 0.3365 - accuracy: 0.8303 - val_loss: 0.2706 - val_accuracy: 0.8764\n","1266/1266 [==============================] - 2s 1ms/step - loss: 0.9435 - accuracy: 0.4747\n","5000/5000 [==============================] - 8s 2ms/step - loss: 0.2819 - accuracy: 0.8672\n","5454\n","881\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:270: RuntimeWarning: invalid value encountered in greater\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hjV7C5b3w1H1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}